{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UC1 - Building with AzureOpenAI realtime API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The GPT-4o audio realtime API is designed to handle real-time, low-latency conversational interactions, making it a great fit for use cases involving live interactions between a user and a model, such as customer support agents, voice assistants, and real-time translators.\n",
    "\n",
    "Azure OpenAI GPT-4o real-time API supports low-latency, \"speech in, speech out\" conversational interactions.\n",
    "It works with text messages, function tool calling, and many other existing capabilities from other endpoints like /chat/completions.\n",
    "Is a great fit for support agents, assistants, translators, and other use cases that need highly responsive back-and-forth with a user.\n",
    "\n",
    "Please review the [GPT-4o Realtime API documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-quickstart?pivots=ai-foundry-portal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model\n",
    "On your Azure AI Foundry Portal choose Models + Endpoints, Deploy Mode / Deploy a base Model and finally choose gpt-4o-realtime as the model to be deployed.\n",
    "\n",
    "![Deploying GPT-4o Realtime API](./images/p1.png)\n",
    "\n",
    "Next, edit the deployment to increase the number of calls per minute to the max value.\n",
    "![Increase calls per minute to the model](./images/p2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPT-4o Azure OpenAI API Endpoint with Completions API \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m AZURE_OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import dotenv\n",
    "    \n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "        \n",
    "# Send a completion call to generate an answer\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages = [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an MIT PhD in Physics, specializing in quantum physics.\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is a black hole?\"\n",
    "        }\n",
    "    ]\n",
    "    # max_tokens=4096\n",
    ")\n",
    "\n",
    "#print(completion.model_dump_json(indent=2))\n",
    "content = completion.choices[0].message.content\n",
    "print(content)\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPT-4o real-time API\n",
    "\n",
    "### Connecting to and authenticating with /realtime\n",
    "\n",
    "The /realtime API requires an existing Azure OpenAI resource endpoint in a supported region. A full request URI can be constructed by concatenating:\n",
    "\n",
    "The secure WebSocket (wss://) protocol\n",
    "Your Azure OpenAI resource endpoint hostname, e.g. my-aoai-resource.openai.azure.com\n",
    "The openai/realtime API path\n",
    "An api-version query string parameter for a supported API version -- initially, 2024-10-01-preview\n",
    "A deployment query string parameter with the name of your gpt-4o-realtime-preview model deployment\n",
    "Combining into a full example, the following could be a well-constructed /realtime request URI:\n",
    "\n",
    "wss://my-eastus2-openai-resource.openai.azure.com/openai/realtime?api-version=2024-10-01-preview&deployment=gpt-4o-realtime-preview-1001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ws (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for ws\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import WebSocket from \"ws\";\n",
    "\n",
    "const url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01\";\n",
    "const ws = new WebSocket(url, {\n",
    "    headers: {\n",
    "        \"Authorization\": \"Bearer \" + process.env.OPENAI_API_KEY,\n",
    "        \"OpenAI-Beta\": \"realtime=v1\",\n",
    "    },\n",
    "});\n",
    "\n",
    "ws.on(\"open\", function open() {\n",
    "    console.log(\"Connected to server.\");\n",
    "    ws.send(JSON.stringify({\n",
    "        type: \"response.create\",\n",
    "        response: {\n",
    "            modalities: [\"text\"],\n",
    "            instructions: \"Please assist the user.\",\n",
    "        }\n",
    "    }));\n",
    "});\n",
    "\n",
    "ws.on(\"message\", function incoming(message) {\n",
    "    console.log(JSON.parse(message.toString()));\n",
    "});\n",
    "\n",
    "\n",
    "\n",
    "[Azure OpenAI GPT-4o Audio and /realtime: Public Preview Documentation](https://github.com/azure-samples/aoai-realtime-audio-sdk)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
